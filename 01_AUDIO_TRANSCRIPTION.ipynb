{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "collapsed": false,
    "name": "cell1",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Call Center Audio Transcription with Snowflake Cortex AI\n",
    "\n",
    "This notebook demonstrates Snowflake's native audio transcription capabilities using the **AI_TRANSCRIBE** function. We'll process real call center audio files and convert them to text for further AI-powered analysis.\n",
    "\n",
    "## What We'll Accomplish:\n",
    "* **Audio File Processing**: Load and process English MP3 call center recordings\n",
    "* **AI-Powered Transcription**: Convert speech to text using Snowflake's built-in AI_TRANSCRIBE function\n",
    "* **Data Foundation**: Create structured tables for downstream AI analytics\n",
    "\n",
    "## Business Value:\n",
    "* **No Complex Setup**: Native Snowflake function - no external services required\n",
    "* **Enterprise Ready**: Secure, scalable audio processing within your data warehouse\n",
    "* **Foundation for Insights**: Transcribed text becomes the foundation for advanced AI analytics\n",
    "\n",
    "**Competing with GONG**: Showcasing Snowflake's integrated approach to call analytics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000001",
   "metadata": {
    "collapsed": false,
    "name": "cell2",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Setup Session and Context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000002",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "# Get active Snowflake session\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "# Set context\n",
    "session.sql(\"USE DATABASE CALL_CENTER_ANALYTICS\").collect()\n",
    "session.sql(\"USE SCHEMA AUDIO_PROCESSING\").collect()\n",
    "session.sql(\"USE WAREHOUSE AUDIO_CORTEX_WH\").collect()\n",
    "\n",
    "st.write(\"âœ… Session setup complete - Ready for audio transcription!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000003",
   "metadata": {
    "name": "cell4",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Explore Available Audio Files\n",
    "Let's examine the call center audio files we'll be processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000004",
   "metadata": {
    "language": "sql",
    "name": "cell5",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- List available English MP3 audio files\n",
    "SELECT \n",
    "    RELATIVE_PATH AS filename,\n",
    "    SIZE AS file_size_bytes,\n",
    "    ROUND(SIZE/1024/1024, 2) AS file_size_mb,\n",
    "    LAST_MODIFIED\n",
    "FROM DIRECTORY('@CALL_CENTER_AUDIO_FILES')\n",
    "WHERE RELATIVE_PATH LIKE '%.mp3'\n",
    "ORDER BY RELATIVE_PATH;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000005",
   "metadata": {
    "name": "cell6",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Audio File Preview\n",
    "Let's listen to our call center recordings to understand what we're working with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000006",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "# Get list of audio files and create interactive player\n",
    "files_df = session.sql(\"\"\"\n",
    "    SELECT \n",
    "        RELATIVE_PATH,\n",
    "        GET_PRESIGNED_URL('@CALL_CENTER_AUDIO_FILES', RELATIVE_PATH) AS URL\n",
    "    FROM DIRECTORY('@CALL_CENTER_AUDIO_FILES')\n",
    "    WHERE RELATIVE_PATH LIKE '%.mp3'\n",
    "    ORDER BY RELATIVE_PATH\n",
    "\"\"\").to_pandas()\n",
    "\n",
    "if not files_df.empty:\n",
    "    selected_file = st.selectbox('ðŸŽ§ Select Call Recording to Listen:', files_df['RELATIVE_PATH'])\n",
    "    \n",
    "    if selected_file:\n",
    "        url = files_df[files_df['RELATIVE_PATH'] == selected_file]['URL'].iloc[0]\n",
    "        st.audio(url, format=\"audio/mpeg\")\n",
    "        st.write(f\"**Playing**: {selected_file}\")\n",
    "else:\n",
    "    st.error(\"No MP3 files found. Please check the setup.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000007",
   "metadata": {
    "name": "cell8",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Audio Transcription with AI_TRANSCRIBE\n",
    "\n",
    "Now for the magic! We'll use Snowflake's native **AI_TRANSCRIBE** function to convert our audio files to text. This function leverages advanced speech recognition models to provide accurate transcriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000008",
   "metadata": {
    "language": "sql",
    "name": "cell9",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create a table to store FILE objects for transcription\n",
    "CREATE OR REPLACE TABLE AUDIO_FILES_FOR_TRANSCRIPTION AS\n",
    "SELECT \n",
    "    RELATIVE_PATH AS filename,\n",
    "    TO_FILE('@CALL_CENTER_AUDIO_FILES', RELATIVE_PATH) AS audio_file\n",
    "FROM DIRECTORY('@CALL_CENTER_AUDIO_FILES')\n",
    "WHERE RELATIVE_PATH LIKE '%.mp3'\n",
    "ORDER BY RELATIVE_PATH;\n",
    "\n",
    "SELECT * FROM AUDIO_FILES_FOR_TRANSCRIPTION;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000009",
   "metadata": {
    "language": "sql",
    "name": "cell10",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Perform AI transcription on our audio files\n",
    "CREATE OR REPLACE TABLE CALL_TRANSCRIPTS AS\n",
    "SELECT \n",
    "    filename AS audio_file_name,\n",
    "    AI_TRANSCRIBE(audio_file):text::STRING AS transcript_text,\n",
    "    CURRENT_TIMESTAMP() AS processing_timestamp\n",
    "FROM AUDIO_FILES_FOR_TRANSCRIPTION;\n",
    "\n",
    "-- View transcription results\n",
    "SELECT * FROM CALL_TRANSCRIPTS;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000010",
   "metadata": {
    "name": "cell11",
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Transcription Results Display\n",
    "\n",
    "Let's create an interactive display of our transcription results with some basic analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000011",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": [
    "# Display transcription results with analysis\n",
    "transcripts_df = session.table('CALL_TRANSCRIPTS').to_pandas()\n",
    "\n",
    "st.markdown(\"### ðŸŽ¯ Transcription Results\")\n",
    "\n",
    "if not transcripts_df.empty:\n",
    "    # Display metrics\n",
    "    col1, col2, col3 = st.columns(3)\n",
    "    \n",
    "    with col1:\n",
    "        st.metric(\"Files Processed\", len(transcripts_df))\n",
    "    \n",
    "    with col2:\n",
    "        avg_length = transcripts_df['TRANSCRIPT_TEXT'].str.len().mean()\n",
    "        st.metric(\"Avg Transcript Length\", f\"{avg_length:.0f} chars\")\n",
    "    \n",
    "    with col3:\n",
    "        total_words = transcripts_df['TRANSCRIPT_TEXT'].str.split().str.len().sum()\n",
    "        st.metric(\"Total Words\", f\"{total_words:,}\")\n",
    "    \n",
    "    # Display individual transcripts\n",
    "    st.markdown(\"### ðŸ“ Individual Call Transcripts\")\n",
    "    \n",
    "    for idx, row in transcripts_df.iterrows():\n",
    "        with st.expander(f\"ðŸ“ž {row['AUDIO_FILE_NAME']}\", expanded=False):\n",
    "            st.write(f\"**Processing Time**: {row['PROCESSING_TIMESTAMP']}\")\n",
    "            st.write(f\"**Transcript Length**: {len(row['TRANSCRIPT_TEXT'])} characters\")\n",
    "            st.write(f\"**Word Count**: {len(row['TRANSCRIPT_TEXT'].split())} words\")\n",
    "            st.text_area(\"Full Transcript:\", row['TRANSCRIPT_TEXT'], height=200, key=f\"transcript_{idx}\")\n",
    "else:\n",
    "    st.error(\"No transcripts found. Please check the transcription process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9dfd8d-023b-4ffb-9518-88e4fb603fb0",
   "metadata": {
    "language": "sql",
    "name": "cell14"
   },
   "outputs": [],
   "source": [
    "-- Apply basic AI functions to our audio transcripts\n",
    "CREATE OR REPLACE TABLE AUDIO_AI_ANALYSIS AS\n",
    "SELECT \n",
    "    audio_file_name,\n",
    "    transcript_text,\n",
    "    processing_timestamp,\n",
    "    -- AI Summarization\n",
    "    SNOWFLAKE.CORTEX.SUMMARIZE(transcript_text) AS call_summary,\n",
    "    -- Sentiment Analysis\n",
    "    SNOWFLAKE.CORTEX.SENTIMENT(transcript_text) AS sentiment_score,\n",
    "    CASE \n",
    "        WHEN SNOWFLAKE.CORTEX.SENTIMENT(transcript_text) >= 0.1 THEN 'ðŸ˜Š Positive'\n",
    "        WHEN SNOWFLAKE.CORTEX.SENTIMENT(transcript_text) <= -0.1 THEN 'ðŸ˜ž Negative'\n",
    "        ELSE 'ðŸ˜ Neutral'\n",
    "    END AS sentiment_category,\n",
    "    -- Basic Classification\n",
    "    AI_CLASSIFY(\n",
    "        transcript_text, \n",
    "        ['Insurance Inquiry', 'Technical Support', 'Complaint', 'Sales Call', 'General Information']\n",
    "    ):labels[0]::STRING AS call_classification\n",
    "FROM CALL_TRANSCRIPTS;\n",
    "\n",
    "-- Display AI analysis results\n",
    "SELECT \n",
    "    audio_file_name,\n",
    "    sentiment_category,\n",
    "    sentiment_score,\n",
    "    call_classification,\n",
    "    call_summary\n",
    "FROM AUDIO_AI_ANALYSIS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d746c-708f-4cf2-9b2e-807c646c2606",
   "metadata": {
    "language": "sql",
    "name": "cell16"
   },
   "outputs": [],
   "source": [
    "-- Add basic priority filtering to audio transcripts\n",
    "CREATE OR REPLACE TABLE AUDIO_PRIORITY_ANALYSIS AS\n",
    "SELECT \n",
    "    *,\n",
    "    -- Check for frustration or dissatisfaction\n",
    "    AI_FILTER(PROMPT('Does this call indicate customer frustration or dissatisfaction? {0}', transcript_text)) AS shows_frustration,\n",
    "    -- Check for urgent requests\n",
    "    AI_FILTER(PROMPT('Does this call contain urgent requests or time-sensitive issues? {0}', transcript_text)) AS urgent_request,\n",
    "    -- Priority level assignment\n",
    "    CASE \n",
    "        WHEN AI_FILTER(PROMPT('Does this call indicate customer frustration or dissatisfaction? {0}', transcript_text)) \n",
    "             AND sentiment_score <= -0.1 THEN 'ðŸ”´ HIGH PRIORITY'\n",
    "        WHEN AI_FILTER(PROMPT('Does this call contain urgent requests or time-sensitive issues? {0}', transcript_text)) THEN 'ðŸŸ¡ MEDIUM PRIORITY'\n",
    "        ELSE 'ðŸŸ¢ STANDARD'\n",
    "    END AS priority_level\n",
    "FROM AUDIO_AI_ANALYSIS;\n",
    "\n",
    "-- Display priority analysis\n",
    "SELECT \n",
    "    audio_file_name,\n",
    "    call_classification,\n",
    "    sentiment_category,\n",
    "    shows_frustration,\n",
    "    urgent_request,\n",
    "    priority_level,\n",
    "    call_summary\n",
    "FROM AUDIO_PRIORITY_ANALYSIS\n",
    "ORDER BY \n",
    "    CASE priority_level \n",
    "        WHEN 'ðŸ”´ HIGH PRIORITY' THEN 1\n",
    "        WHEN 'ðŸŸ¡ MEDIUM PRIORITY' THEN 2\n",
    "        ELSE 3\n",
    "    END;\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "authorEmail": "harley.chen@snowflake.com",
   "authorId": "167081822753",
   "authorName": "HCHEN",
   "lastEditTime": 1750348092657,
   "notebookId": "sal2uszxvb7tmvx4rkhe",
   "sessionId": "2f61088a-f7f5-48b6-a382-1e9e8e31e8af"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
