{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Call Center Audio Transcription with Snowflake Cortex AI\n",
        "\n",
        "This notebook demonstrates Snowflake's native audio transcription capabilities using the **AI_TRANSCRIBE** function. We'll process real call center audio files and convert them to text for further AI-powered analysis.\n",
        "\n",
        "## What We'll Accomplish:\n",
        "* **Audio File Processing**: Load and process English MP3 call center recordings\n",
        "* **AI-Powered Transcription**: Convert speech to text using Snowflake's built-in AI_TRANSCRIBE function\n",
        "* **Data Foundation**: Create structured tables for downstream AI analytics\n",
        "\n",
        "## Business Value:\n",
        "* **No Complex Setup**: Native Snowflake function - no external services required\n",
        "* **Enterprise Ready**: Secure, scalable audio processing within your data warehouse\n",
        "* **Foundation for Insights**: Transcribed text becomes the foundation for advanced AI analytics\n",
        "\n",
        "**Competing with GONG**: Showcasing Snowflake's integrated approach to call analytics\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup Session and Context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import python packages\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "\n",
        "from snowflake.snowpark.functions import *\n",
        "from snowflake.snowpark.types import *\n",
        "\n",
        "# Get active Snowflake session\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "session = get_active_session()\n",
        "\n",
        "# Set context\n",
        "session.sql(\"USE DATABASE CALL_CENTER_ANALYTICS\").collect()\n",
        "session.sql(\"USE SCHEMA AUDIO_PROCESSING\").collect()\n",
        "session.sql(\"USE WAREHOUSE AUDIO_CORTEX_WH\").collect()\n",
        "\n",
        "st.write(\"‚úÖ Session setup complete - Ready for audio transcription!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Explore Available Audio Files\n",
        "Let's examine the call center audio files we'll be processing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- List available English MP3 audio files\n",
        "SELECT \n",
        "    RELATIVE_PATH AS filename,\n",
        "    SIZE AS file_size_bytes,\n",
        "    ROUND(SIZE/1024/1024, 2) AS file_size_mb,\n",
        "    LAST_MODIFIED\n",
        "FROM DIRECTORY('@CALL_CENTER_AUDIO_FILES')\n",
        "WHERE RELATIVE_PATH LIKE '%.mp3'\n",
        "ORDER BY RELATIVE_PATH;\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Audio File Preview\n",
        "Let's listen to our call center recordings to understand what we're working with.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get list of audio files and create interactive player\n",
        "files_df = session.sql(\"\"\"\n",
        "    SELECT \n",
        "        RELATIVE_PATH,\n",
        "        GET_PRESIGNED_URL('@CALL_CENTER_AUDIO_FILES', RELATIVE_PATH) AS URL\n",
        "    FROM DIRECTORY('@CALL_CENTER_AUDIO_FILES')\n",
        "    WHERE RELATIVE_PATH LIKE '%.mp3'\n",
        "    ORDER BY RELATIVE_PATH\n",
        "\"\"\").to_pandas()\n",
        "\n",
        "if not files_df.empty:\n",
        "    selected_file = st.selectbox('üéß Select Call Recording to Listen:', files_df['RELATIVE_PATH'])\n",
        "    \n",
        "    if selected_file:\n",
        "        url = files_df[files_df['RELATIVE_PATH'] == selected_file]['URL'].iloc[0]\n",
        "        st.audio(url, format=\"audio/mpeg\")\n",
        "        st.write(f\"**Playing**: {selected_file}\")\n",
        "else:\n",
        "    st.error(\"No MP3 files found. Please check the setup.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Audio Transcription with AI_TRANSCRIBE\n",
        "\n",
        "Now for the magic! We'll use Snowflake's native **AI_TRANSCRIBE** function to convert our audio files to text. This function leverages advanced speech recognition models to provide accurate transcriptions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Create a table to store FILE objects for transcription\n",
        "CREATE OR REPLACE TABLE AUDIO_FILES_FOR_TRANSCRIPTION AS\n",
        "SELECT \n",
        "    RELATIVE_PATH AS filename,\n",
        "    TO_FILE('@CALL_CENTER_AUDIO_FILES', RELATIVE_PATH) AS audio_file\n",
        "FROM DIRECTORY('@CALL_CENTER_AUDIO_FILES')\n",
        "WHERE RELATIVE_PATH LIKE '%.mp3'\n",
        "ORDER BY RELATIVE_PATH;\n",
        "\n",
        "SELECT * FROM AUDIO_FILES_FOR_TRANSCRIPTION;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Perform AI transcription on our audio files\n",
        "CREATE OR REPLACE TABLE CALL_TRANSCRIPTS AS\n",
        "SELECT \n",
        "    filename AS audio_file_name,\n",
        "    AI_TRANSCRIBE(audio_file) AS transcript_text,\n",
        "    CURRENT_TIMESTAMP() AS processing_timestamp\n",
        "FROM AUDIO_FILES_FOR_TRANSCRIPTION;\n",
        "\n",
        "-- View transcription results\n",
        "SELECT * FROM CALL_TRANSCRIPTS;\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Transcription Results Display\n",
        "\n",
        "Let's create an interactive display of our transcription results with some basic analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display transcription results with analysis\n",
        "transcripts_df = session.table('CALL_TRANSCRIPTS').to_pandas()\n",
        "\n",
        "st.markdown(\"### üéØ Transcription Results\")\n",
        "\n",
        "if not transcripts_df.empty:\n",
        "    # Display metrics\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "    \n",
        "    with col1:\n",
        "        st.metric(\"Files Processed\", len(transcripts_df))\n",
        "    \n",
        "    with col2:\n",
        "        avg_length = transcripts_df['TRANSCRIPT_TEXT'].str.len().mean()\n",
        "        st.metric(\"Avg Transcript Length\", f\"{avg_length:.0f} chars\")\n",
        "    \n",
        "    with col3:\n",
        "        total_words = transcripts_df['TRANSCRIPT_TEXT'].str.split().str.len().sum()\n",
        "        st.metric(\"Total Words\", f\"{total_words:,}\")\n",
        "    \n",
        "    # Display individual transcripts\n",
        "    st.markdown(\"### üìù Individual Call Transcripts\")\n",
        "    \n",
        "    for idx, row in transcripts_df.iterrows():\n",
        "        with st.expander(f\"üìû {row['AUDIO_FILE_NAME']}\", expanded=False):\n",
        "            st.write(f\"**Processing Time**: {row['PROCESSING_TIMESTAMP']}\")\n",
        "            st.write(f\"**Transcript Length**: {len(row['TRANSCRIPT_TEXT'])} characters\")\n",
        "            st.write(f\"**Word Count**: {len(row['TRANSCRIPT_TEXT'].split())} words\")\n",
        "            st.text_area(\"Full Transcript:\", row['TRANSCRIPT_TEXT'], height=200, key=f\"transcript_{idx}\")\n",
        "else:\n",
        "    st.error(\"No transcripts found. Please check the transcription process.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üöÄ Next Steps: Preparing for AI Analytics\n",
        "\n",
        "**Congratulations!** You've successfully transcribed call center audio files using Snowflake's native AI capabilities.\n",
        "\n",
        "### What We've Accomplished:\n",
        "‚úÖ **Loaded Audio Files**: Ingested English MP3 call center recordings  \n",
        "‚úÖ **AI Transcription**: Converted speech to text using AI_TRANSCRIBE  \n",
        "‚úÖ **Data Foundation**: Created structured tables for downstream analysis  \n",
        "‚úÖ **Quality Assessment**: Verified transcription quality and readiness  \n",
        "\n",
        "### Ready for Advanced AI Analytics:\n",
        "Our transcribed text is now ready for:\n",
        "- **Sentiment Analysis** with SNOWFLAKE.CORTEX.SENTIMENT\n",
        "- **Call Classification** with AI_CLASSIFY\n",
        "- **Priority Filtering** with AI_FILTER\n",
        "- **Executive Summaries** with AI_SUMMARIZE\n",
        "- **Structured Data Extraction** with AI_COMPLETE\n",
        "\n",
        "**Next Notebook**: `02_CORTEX_AI_ANALYTICS.ipynb` - Advanced AI-powered call analysis\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
