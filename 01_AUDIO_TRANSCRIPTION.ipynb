{
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "notebookId": "sal2uszxvb7tmvx4rkhe",
   "authorId": "167081822753",
   "authorName": "HCHEN",
   "authorEmail": "harley.chen@snowflake.com",
   "sessionId": "c48aa7a5-a69b-467f-9ea9-b5994edbb71d",
   "lastEditTime": 1752067395235
  }
 },
 "nbformat_minor": 2,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell1",
    "collapsed": false
   },
   "source": "# Call Center Audio Transcription with Snowflake Cortex AI\n\nThis notebook demonstrates Snowflake's native audio transcription capabilities using the **AI_TRANSCRIBE** function. We'll process real call center audio files and convert them to text for further AI-powered analysis.\n\n## What We'll Accomplish:\n* **Audio File Processing**: Load and process English MP3 call center recordings\n* **AI-Powered Transcription**: Convert speech to text using Snowflake's built-in AI_TRANSCRIBE function\n* **Data Foundation**: Create structured tables for downstream AI analytics\n\n## Business Value:\n* **No Complex Setup**: Native Snowflake function - no external services required\n* **Enterprise Ready**: Secure, scalable audio processing within your data warehouse\n* **Foundation for Insights**: Transcribed text becomes the foundation for advanced AI analytics",
   "id": "ce110000-1111-2222-3333-ffffff000000"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell2",
    "collapsed": false
   },
   "source": [
    "## Setup Session and Context\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000001"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell3",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "# Get active Snowflake session\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "# Set context\n",
    "session.sql(\"USE DATABASE CALL_CENTER_ANALYTICS\").collect()\n",
    "session.sql(\"USE SCHEMA AUDIO_PROCESSING\").collect()\n",
    "session.sql(\"USE WAREHOUSE AUDIO_CORTEX_WH\").collect()\n",
    "\n",
    "st.write(\"âœ… Session setup complete - Ready for audio transcription!\")\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000002"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell4"
   },
   "source": [
    "## Explore Available Audio Files\n",
    "Let's examine the call center audio files we'll be processing.\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000003"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "cell5",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- List available English MP3 audio files\nSELECT \n    RELATIVE_PATH AS filename,\n    SIZE AS file_size_bytes,\n    ROUND(SIZE/1024/1024, 2) AS file_size_mb,\n    LAST_MODIFIED\nFROM DIRECTORY('@CALL_CENTER_AUDIO_FILES')\nWHERE RELATIVE_PATH LIKE '%.mp3'\nORDER BY RELATIVE_PATH;",
   "id": "ce110000-1111-2222-3333-ffffff000004"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell6"
   },
   "source": [
    "## Audio File Preview\n",
    "Let's listen to our call center recordings to understand what we're working with.\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000005"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell7",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Get list of audio files and create interactive player\n",
    "files_df = session.sql(\"\"\"\n",
    "    SELECT \n",
    "        RELATIVE_PATH,\n",
    "        GET_PRESIGNED_URL('@CALL_CENTER_AUDIO_FILES', RELATIVE_PATH) AS URL\n",
    "    FROM DIRECTORY('@CALL_CENTER_AUDIO_FILES')\n",
    "    WHERE RELATIVE_PATH LIKE '%.mp3'\n",
    "    ORDER BY RELATIVE_PATH\n",
    "\"\"\").to_pandas()\n",
    "\n",
    "if not files_df.empty:\n",
    "    selected_file = st.selectbox('ðŸŽ§ Select Call Recording to Listen:', files_df['RELATIVE_PATH'])\n",
    "    \n",
    "    if selected_file:\n",
    "        url = files_df[files_df['RELATIVE_PATH'] == selected_file]['URL'].iloc[0]\n",
    "        st.audio(url, format=\"audio/mpeg\")\n",
    "        st.write(f\"**Playing**: {selected_file}\")\n",
    "else:\n",
    "    st.error(\"No MP3 files found. Please check the setup.\")\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000006"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell8"
   },
   "source": [
    "## Audio Transcription with AI_TRANSCRIBE\n",
    "\n",
    "Now for the magic! We'll use Snowflake's native **AI_TRANSCRIBE** function to convert our audio files to text. This function leverages advanced speech recognition models to provide accurate transcriptions.\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000007"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "cell9",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Create a table to store FILE objects for transcription\n",
    "CREATE OR REPLACE TABLE AUDIO_FILES_FOR_TRANSCRIPTION AS\n",
    "SELECT \n",
    "    RELATIVE_PATH AS filename,\n",
    "    TO_FILE('@CALL_CENTER_AUDIO_FILES', RELATIVE_PATH) AS audio_file\n",
    "FROM DIRECTORY('@CALL_CENTER_AUDIO_FILES')\n",
    "WHERE RELATIVE_PATH LIKE '%.mp3'\n",
    "ORDER BY RELATIVE_PATH;\n",
    "\n",
    "SELECT * FROM AUDIO_FILES_FOR_TRANSCRIPTION;\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000008"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "cell10",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- Perform AI transcription on our audio files\nCREATE OR REPLACE TABLE CALL_TRANSCRIPTS AS\nSELECT \n    filename AS audio_file_name,\n    AI_TRANSCRIBE(audio_file):text::STRING AS transcript_text,\n    CURRENT_TIMESTAMP() AS processing_timestamp\nFROM AUDIO_FILES_FOR_TRANSCRIPTION;\n\n-- View transcription results\nSELECT * FROM CALL_TRANSCRIPTS;",
   "id": "ce110000-1111-2222-3333-ffffff000009"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "cell11"
   },
   "source": [
    "## Transcription Results Display\n",
    "\n",
    "Let's create an interactive display of our transcription results with some basic analysis.\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000010"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell12",
    "language": "python",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": [
    "# Display transcription results with analysis\n",
    "transcripts_df = session.table('CALL_TRANSCRIPTS').to_pandas()\n",
    "\n",
    "st.markdown(\"### ðŸŽ¯ Transcription Results\")\n",
    "\n",
    "if not transcripts_df.empty:\n",
    "    # Display metrics\n",
    "    col1, col2, col3 = st.columns(3)\n",
    "    \n",
    "    with col1:\n",
    "        st.metric(\"Files Processed\", len(transcripts_df))\n",
    "    \n",
    "    with col2:\n",
    "        avg_length = transcripts_df['TRANSCRIPT_TEXT'].str.len().mean()\n",
    "        st.metric(\"Avg Transcript Length\", f\"{avg_length:.0f} chars\")\n",
    "    \n",
    "    with col3:\n",
    "        total_words = transcripts_df['TRANSCRIPT_TEXT'].str.split().str.len().sum()\n",
    "        st.metric(\"Total Words\", f\"{total_words:,}\")\n",
    "    \n",
    "    # Display individual transcripts\n",
    "    st.markdown(\"### ðŸ“ Individual Call Transcripts\")\n",
    "    \n",
    "    for idx, row in transcripts_df.iterrows():\n",
    "        with st.expander(f\"ðŸ“ž {row['AUDIO_FILE_NAME']}\", expanded=False):\n",
    "            st.write(f\"**Processing Time**: {row['PROCESSING_TIMESTAMP']}\")\n",
    "            st.write(f\"**Transcript Length**: {len(row['TRANSCRIPT_TEXT'])} characters\")\n",
    "            st.write(f\"**Word Count**: {len(row['TRANSCRIPT_TEXT'].split())} words\")\n",
    "            st.text_area(\"Full Transcript:\", row['TRANSCRIPT_TEXT'], height=200, key=f\"transcript_{idx}\")\n",
    "else:\n",
    "    st.error(\"No transcripts found. Please check the transcription process.\")\n"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000011"
  },
  {
   "cell_type": "code",
   "id": "ca9dfd8d-023b-4ffb-9518-88e4fb603fb0",
   "metadata": {
    "language": "sql",
    "name": "cell14"
   },
   "outputs": [],
   "source": "-- Apply basic AI functions to our audio transcripts\nCREATE OR REPLACE TABLE AUDIO_AI_ANALYSIS AS\nSELECT \n    audio_file_name,\n    transcript_text,\n    processing_timestamp,\n    -- AI Summarization\n    SNOWFLAKE.CORTEX.SUMMARIZE(transcript_text) AS call_summary,\n    -- Sentiment Analysis\n    SNOWFLAKE.CORTEX.SENTIMENT(transcript_text) AS sentiment_score,\n    CASE \n        WHEN SNOWFLAKE.CORTEX.SENTIMENT(transcript_text) >= 0.1 THEN 'ðŸ˜Š Positive'\n        WHEN SNOWFLAKE.CORTEX.SENTIMENT(transcript_text) <= -0.1 THEN 'ðŸ˜ž Negative'\n        ELSE 'ðŸ˜ Neutral'\n    END AS sentiment_category,\n    -- Basic Classification\n    AI_CLASSIFY(\n        transcript_text, \n        ['Insurance Inquiry', 'Technical Support', 'Complaint', 'Sales Call', 'General Information']\n    ):labels[0]::STRING AS call_classification\nFROM CALL_TRANSCRIPTS;\n\n-- Display AI analysis results\nSELECT \n    audio_file_name,\n    sentiment_category,\n    sentiment_score,\n    call_classification,\n    call_summary\nFROM AUDIO_AI_ANALYSIS;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5a7d746c-708f-4cf2-9b2e-807c646c2606",
   "metadata": {
    "language": "sql",
    "name": "cell16"
   },
   "outputs": [],
   "source": "-- Add basic priority filtering to audio transcripts\nCREATE OR REPLACE TABLE AUDIO_PRIORITY_ANALYSIS AS\nSELECT \n    *,\n    -- Check for frustration or dissatisfaction\n    AI_FILTER(PROMPT('Does this call indicate customer frustration or dissatisfaction? {0}', transcript_text)) AS shows_frustration,\n    -- Check for urgent requests\n    AI_FILTER(PROMPT('Does this call contain urgent requests or time-sensitive issues? {0}', transcript_text)) AS urgent_request,\n    -- Priority level assignment\n    CASE \n        WHEN AI_FILTER(PROMPT('Does this call indicate customer frustration or dissatisfaction? {0}', transcript_text)) \n             AND sentiment_score <= -0.1 THEN 'ðŸ”´ HIGH PRIORITY'\n        WHEN AI_FILTER(PROMPT('Does this call contain urgent requests or time-sensitive issues? {0}', transcript_text)) THEN 'ðŸŸ¡ MEDIUM PRIORITY'\n        ELSE 'ðŸŸ¢ STANDARD'\n    END AS priority_level\nFROM AUDIO_AI_ANALYSIS;\n\n-- Display priority analysis\nSELECT \n    audio_file_name,\n    call_classification,\n    sentiment_category,\n    shows_frustration,\n    urgent_request,\n    priority_level,\n    call_summary\nFROM AUDIO_PRIORITY_ANALYSIS\nORDER BY \n    CASE priority_level \n        WHEN 'ðŸ”´ HIGH PRIORITY' THEN 1\n        WHEN 'ðŸŸ¡ MEDIUM PRIORITY' THEN 2\n        ELSE 3\n    END;\n",
   "execution_count": null
  }
 ]
}