{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Advanced Customer Communication Analytics with Snowflake Cortex AI\n",
        "\n",
        "This notebook demonstrates Snowflake's advanced AI capabilities for customer communication analytics, competing directly with GONG's intelligent conversation analytics platform.\n",
        "\n",
        "## What We'll Accomplish:\n",
        "* **AI-Powered Summarization**: Generate executive summaries of customer communications\n",
        "* **Sentiment Analysis**: Track customer satisfaction across email interactions\n",
        "* **Intelligent Classification**: Automatically categorize communication types (complaints, inquiries, technical issues)\n",
        "* **Smart Filtering**: Identify priority communications and escalation needs\n",
        "* **Structured Data Extraction**: Extract comprehensive customer intelligence from emails\n",
        "* **Combined AI Operations**: Demonstrate powerful AI function combinations\n",
        "\n",
        "## Business Value - Competing with GONG:\n",
        "* **Integrated Platform**: No separate analytics platform needed - analyze audio AND email communications\n",
        "* **Real-time Processing**: Immediate insights within your data warehouse\n",
        "* **Multi-modal Analysis**: Process both transcribed audio and email communications\n",
        "* **Advanced AI Functions**: State-of-the-art conversation intelligence\n",
        "* **Enterprise Security**: Data never leaves your Snowflake environment\n",
        "* **Cost Efficiency**: No per-seat licensing, usage-based pricing\n",
        "\n",
        "## Dataset Advantage:\n",
        "We're using **real customer service email communications** (3,000+ emails) instead of simple audio transcripts to demonstrate the full power of Snowflake's AI capabilities with rich, contextual conversational data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup session and imports\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from snowflake.snowpark.functions import *\n",
        "from snowflake.snowpark.types import *\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "\n",
        "session = get_active_session()\n",
        "\n",
        "# Set context\n",
        "session.sql(\"USE DATABASE CALL_CENTER_ANALYTICS\").collect()\n",
        "session.sql(\"USE SCHEMA AUDIO_PROCESSING\").collect()\n",
        "session.sql(\"USE WAREHOUSE AUDIO_CORTEX_WH\").collect()\n",
        "\n",
        "# Display dataset overview\n",
        "email_stats = session.sql(\"\"\"\n",
        "    SELECT \n",
        "        COUNT(*) AS total_emails,\n",
        "        COUNT(DISTINCT CUSTOMER_ID) AS unique_customers,\n",
        "        MIN(DATE_RECEIVED) AS earliest_email,\n",
        "        MAX(DATE_RECEIVED) AS latest_email\n",
        "    FROM CUSTOMER_EMAILS\n",
        "\"\"\").collect()[0]\n",
        "\n",
        "col1, col2, col3, col4 = st.columns(4)\n",
        "with col1:\n",
        "    st.metric(\"ðŸ“§ Total Emails\", f\"{email_stats['TOTAL_EMAILS']:,}\")\n",
        "with col2:\n",
        "    st.metric(\"ðŸ‘¥ Unique Customers\", f\"{email_stats['UNIQUE_CUSTOMERS']:,}\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ðŸ“Š AI_SUMMARIZE - Executive Communication Summaries (First Impact!)\n",
        "\n",
        "Let's start with the most visually impactful feature - generating executive summaries of customer communications. This immediately shows the power of AI to distill lengthy email conversations into actionable insights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Generate executive summaries for customer emails (sample first to manage costs)\n",
        "CREATE OR REPLACE TABLE EMAIL_SUMMARIES AS\n",
        "SELECT \n",
        "    EMAIL_ID,\n",
        "    CUSTOMER_ID,\n",
        "    DATE_RECEIVED,\n",
        "    EMAIL_CONTENTS,\n",
        "    SNOWFLAKE.CORTEX.SUMMARIZE(EMAIL_CONTENTS) AS executive_summary,\n",
        "    CURRENT_TIMESTAMP() AS processing_timestamp\n",
        "FROM CUSTOMER_EMAILS\n",
        "WHERE DATE_RECEIVED >= '2025-04-10'  -- Focus on recent emails for demo\n",
        "LIMIT 50;  -- Sample for cost management during demo\n",
        "\n",
        "-- Display the result\n",
        "SELECT \n",
        "    EMAIL_ID,\n",
        "    CUSTOMER_ID,\n",
        "    DATE_RECEIVED,\n",
        "    LEFT(EMAIL_CONTENTS, 150) || '...' AS email_preview,\n",
        "    executive_summary\n",
        "FROM EMAIL_SUMMARIES\n",
        "ORDER BY DATE_RECEIVED DESC\n",
        "LIMIT 10;\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ðŸ’­ Combined Sentiment Analysis & Classification\n",
        "\n",
        "Understanding customer sentiment and automatically categorizing communications is crucial for customer service operations. Let's analyze both the emotional tone and business categories of our customer communications in one comprehensive step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Combined sentiment analysis and classification in one step\n",
        "CREATE OR REPLACE TABLE EMAIL_SENTIMENT_CLASSIFICATION AS\n",
        "SELECT \n",
        "    es.*,\n",
        "    -- Sentiment Analysis\n",
        "    SNOWFLAKE.CORTEX.SENTIMENT(EMAIL_CONTENTS) AS sentiment_score,\n",
        "    CASE \n",
        "        WHEN SNOWFLAKE.CORTEX.SENTIMENT(EMAIL_CONTENTS) >= 0.1 THEN 'ðŸ˜Š Positive'\n",
        "        WHEN SNOWFLAKE.CORTEX.SENTIMENT(EMAIL_CONTENTS) <= -0.1 THEN 'ðŸ˜ž Negative'\n",
        "        ELSE 'ðŸ˜ Neutral'\n",
        "    END AS sentiment_category,\n",
        "    -- Classification\n",
        "    AI_CLASSIFY(\n",
        "        EMAIL_CONTENTS, \n",
        "        ['Complaint', 'Inquiry', 'Compliment', 'Technical Support', 'Billing Issue', 'General Information']\n",
        "    ):labels[0]::STRING AS email_classification\n",
        "FROM EMAIL_SUMMARIES es;\n",
        "\n",
        "-- Display combined analysis results\n",
        "SELECT \n",
        "    EMAIL_ID,\n",
        "    CUSTOMER_ID,\n",
        "    sentiment_score,\n",
        "    sentiment_category,\n",
        "    email_classification,\n",
        "    LEFT(executive_summary, 100) || '...' AS summary_preview\n",
        "FROM EMAIL_SENTIMENT_CLASSIFICATION\n",
        "ORDER BY sentiment_score DESC\n",
        "LIMIT 10;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comprehensive sentiment and classification visualization\n",
        "st.markdown(\"### ðŸ“Š Customer Communication Analytics Dashboard\")\n",
        "\n",
        "# Get combined data\n",
        "combined_df = session.sql(\"\"\"\n",
        "    SELECT \n",
        "        sentiment_category,\n",
        "        email_classification,\n",
        "        COUNT(*) as count,\n",
        "        ROUND(AVG(sentiment_score), 3) as avg_score\n",
        "    FROM EMAIL_SENTIMENT_CLASSIFICATION\n",
        "    GROUP BY sentiment_category, email_classification\n",
        "    ORDER BY count DESC\n",
        "\"\"\").to_pandas()\n",
        "\n",
        "# Sentiment distribution\n",
        "sentiment_df = session.sql(\"\"\"\n",
        "    SELECT \n",
        "        sentiment_category,\n",
        "        COUNT(*) as count,\n",
        "        ROUND(AVG(sentiment_score), 3) as avg_score\n",
        "    FROM EMAIL_SENTIMENT_CLASSIFICATION\n",
        "    GROUP BY sentiment_category\n",
        "    ORDER BY count DESC\n",
        "\"\"\").to_pandas()\n",
        "\n",
        "# Classification distribution\n",
        "classification_df = session.sql(\"\"\"\n",
        "    SELECT \n",
        "        email_classification,\n",
        "        COUNT(*) as count,\n",
        "        ROUND(AVG(sentiment_score), 3) as avg_sentiment\n",
        "    FROM EMAIL_SENTIMENT_CLASSIFICATION\n",
        "    GROUP BY email_classification\n",
        "    ORDER BY count DESC\n",
        "\"\"\").to_pandas()\n",
        "\n",
        "if not sentiment_df.empty and not classification_df.empty:\n",
        "    # Create two-column layout for both visualizations\n",
        "    col1, col2 = st.columns(2)\n",
        "    \n",
        "    with col1:\n",
        "        st.markdown(\"#### ðŸ’­ Sentiment Distribution\")\n",
        "        \n",
        "        # Snowflake brand colors for sentiment\n",
        "        sentiment_colors = {\n",
        "            'ðŸ˜Š Positive': '#10B981',    # Modern green\n",
        "            'ðŸ˜ Neutral': '#29B5E8',     # Snowflake blue\n",
        "            'ðŸ˜ž Negative': '#EF4444'     # Modern red\n",
        "        }\n",
        "        \n",
        "        colors = [sentiment_colors.get(cat, '#64748B') for cat in sentiment_df['SENTIMENT_CATEGORY']]\n",
        "        \n",
        "        # Create sentiment pie chart\n",
        "        fig1, ax1 = plt.subplots(figsize=(8, 6))\n",
        "        wedges, texts, autotexts = ax1.pie(\n",
        "            sentiment_df['COUNT'], \n",
        "            labels=sentiment_df['SENTIMENT_CATEGORY'],\n",
        "            autopct='%1.1f%%',\n",
        "            colors=colors,\n",
        "            startangle=90,\n",
        "            textprops={'fontsize': 10, 'fontweight': 'bold'},\n",
        "            wedgeprops={'edgecolor': 'white', 'linewidth': 2}\n",
        "        )\n",
        "        ax1.set_title('Customer Sentiment', fontsize=14, fontweight='bold', color='#1E293B', pad=15)\n",
        "        ax1.axis('equal')\n",
        "        st.pyplot(fig1, clear_figure=True)\n",
        "        \n",
        "        # Sentiment metrics\n",
        "        for idx, row in sentiment_df.iterrows():\n",
        "            st.metric(\n",
        "                label=f\"{row['SENTIMENT_CATEGORY']}\",\n",
        "                value=f\"{row['COUNT']} emails\",\n",
        "                delta=f\"Avg: {row['AVG_SCORE']}\"\n",
        "            )\n",
        "    \n",
        "    with col2:\n",
        "        st.markdown(\"#### ðŸ·ï¸ Communication Types\")\n",
        "        \n",
        "        # Classification colors (using a professional palette)\n",
        "        classification_colors = ['#29B5E8', '#10B981', '#EF4444', '#F59E0B', '#8B5CF6', '#06B6D4']\n",
        "        \n",
        "        # Create classification pie chart\n",
        "        fig2, ax2 = plt.subplots(figsize=(8, 6))\n",
        "        wedges, texts, autotexts = ax2.pie(\n",
        "            classification_df['COUNT'], \n",
        "            labels=classification_df['EMAIL_CLASSIFICATION'],\n",
        "            autopct='%1.1f%%',\n",
        "            colors=classification_colors[:len(classification_df)],\n",
        "            startangle=90,\n",
        "            textprops={'fontsize': 10, 'fontweight': 'bold'},\n",
        "            wedgeprops={'edgecolor': 'white', 'linewidth': 2}\n",
        "        )\n",
        "        ax2.set_title('Communication Categories', fontsize=14, fontweight='bold', color='#1E293B', pad=15)\n",
        "        ax2.axis('equal')\n",
        "        st.pyplot(fig2, clear_figure=True)\n",
        "        \n",
        "        # Classification metrics\n",
        "        for idx, row in classification_df.iterrows():\n",
        "            st.metric(\n",
        "                label=f\"{row['EMAIL_CLASSIFICATION']}\",\n",
        "                value=f\"{row['COUNT']} emails\",\n",
        "                delta=f\"Avg Sentiment: {row['AVG_SENTIMENT']}\"\n",
        "            )\n",
        "    \n",
        "    # Combined insights\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"#### ðŸ” Key Insights\")\n",
        "    \n",
        "    col_insight1, col_insight2 = st.columns(2)\n",
        "    \n",
        "    with col_insight1:\n",
        "        total_emails = sentiment_df['COUNT'].sum()\n",
        "        positive_pct = (sentiment_df[sentiment_df['SENTIMENT_CATEGORY'] == 'ðŸ˜Š Positive']['COUNT'].sum() / total_emails * 100) if total_emails > 0 else 0\n",
        "        st.info(f\"ðŸ’¡ **Sentiment**: {positive_pct:.1f}% of communications show positive sentiment\")\n",
        "    \n",
        "    with col_insight2:\n",
        "        top_category = classification_df.iloc[0]['EMAIL_CLASSIFICATION'] if len(classification_df) > 0 else \"N/A\"\n",
        "        top_count = classification_df.iloc[0]['COUNT'] if len(classification_df) > 0 else 0\n",
        "        st.info(f\"ðŸ“ˆ **Top Category**: {top_category} ({top_count} emails)\")\n",
        "    \n",
        "    # Show combined sentiment-classification breakdown\n",
        "    if not combined_df.empty:\n",
        "        st.markdown(\"#### ðŸ“‹ Detailed Breakdown: Sentiment by Category\")\n",
        "        \n",
        "        # Create a pivot table for better display\n",
        "        pivot_df = combined_df.pivot_table(\n",
        "            index='EMAIL_CLASSIFICATION', \n",
        "            columns='SENTIMENT_CATEGORY', \n",
        "            values='COUNT', \n",
        "            fill_value=0\n",
        "        )\n",
        "        \n",
        "        st.dataframe(pivot_df, use_container_width=True)\n",
        "\n",
        "else:\n",
        "    st.error(\"No data found. Please run the previous analysis steps.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ðŸš¨ AI_FILTER - Smart Priority Identification\n",
        "\n",
        "Identify customer communications that need immediate attention or escalation using intelligent filtering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Add intelligent filtering for escalation and priority identification\n",
        "CREATE OR REPLACE TABLE EMAIL_PRIORITY_ANALYSIS AS\n",
        "SELECT \n",
        "    esc.*,\n",
        "    AI_FILTER(PROMPT('Does this customer email indicate the request needs escalating? {0}', EMAIL_CONTENTS)) AS needs_escalation,\n",
        "    AI_FILTER(PROMPT('Is this customer expressing dissatisfaction or frustration? {0}', EMAIL_CONTENTS)) AS high_priority_email\n",
        "FROM EMAIL_SENTIMENT_CLASSIFICATION esc;\n",
        "\n",
        "-- Display priority analysis results\n",
        "SELECT \n",
        "    EMAIL_ID,\n",
        "    email_classification,\n",
        "    sentiment_category,\n",
        "    needs_escalation,\n",
        "    high_priority_email,\n",
        "    CASE \n",
        "        WHEN needs_escalation AND high_priority_email THEN 'ðŸ”´ URGENT'\n",
        "        WHEN needs_escalation OR high_priority_email THEN 'ðŸŸ¡ PRIORITY'\n",
        "        ELSE 'ðŸŸ¢ STANDARD'\n",
        "    END AS priority_level\n",
        "FROM EMAIL_PRIORITY_ANALYSIS;\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ðŸš¨ AI_FILTER - Smart Priority Identification\n",
        "\n",
        "Identify customer communications that need immediate attention or escalation using intelligent filtering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Add intelligent filtering for escalation and priority identification\n",
        "CREATE OR REPLACE TABLE EMAIL_PRIORITY_ANALYSIS AS\n",
        "SELECT \n",
        "    esc.*,\n",
        "    AI_FILTER(PROMPT('Does this customer email indicate the request needs escalating? {0}', EMAIL_CONTENTS)) AS needs_escalation,\n",
        "    AI_FILTER(PROMPT('Is this customer expressing dissatisfaction or frustration? {0}', EMAIL_CONTENTS)) AS high_priority_email\n",
        "FROM EMAIL_SENTIMENT_CLASSIFICATION esc;\n",
        "\n",
        "-- Display priority analysis results\n",
        "SELECT \n",
        "    EMAIL_ID,\n",
        "    email_classification,\n",
        "    sentiment_category,\n",
        "    needs_escalation,\n",
        "    high_priority_email,\n",
        "    CASE \n",
        "        WHEN needs_escalation AND high_priority_email THEN 'ðŸ”´ URGENT'\n",
        "        WHEN needs_escalation OR high_priority_email THEN 'ðŸŸ¡ PRIORITY'\n",
        "        ELSE 'ðŸŸ¢ STANDARD'\n",
        "    END AS priority_level\n",
        "FROM EMAIL_PRIORITY_ANALYSIS;\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ðŸŽ¯ AI_COMPLETE - Comprehensive Customer Intelligence (GONG Competitor!)\n",
        "\n",
        "This is where we compete directly with GONG - extracting comprehensive, structured customer communication intelligence that provides deep business insights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Extract comprehensive customer intelligence using AI_COMPLETE with structured output\n",
        "CREATE OR REPLACE TABLE COMPREHENSIVE_EMAIL_INTELLIGENCE AS\n",
        "SELECT \n",
        "    epa.EMAIL_ID,\n",
        "    epa.EMAIL_CONTENTS,\n",
        "    epa.executive_summary,\n",
        "    epa.sentiment_score,\n",
        "    epa.email_classification,\n",
        "    AI_COMPLETE(\n",
        "        model => 'snowflake-arctic',\n",
        "        prompt => 'Extract comprehensive customer service analytics from this customer email. Focus on actionable business insights that would compete with GONG platform capabilities: ' || epa.EMAIL_CONTENTS,\n",
        "        response_format => {\n",
        "            'type': 'json',\n",
        "            'schema': {\n",
        "                'type': 'object',\n",
        "                'properties': {\n",
        "                    'communication_summary': {'type': 'string', 'description': 'Brief overview of the entire customer communication'},\n",
        "                    'key_topics_discussed': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Main topics covered in the email'},\n",
        "                    'customer_sentiment': {'type': 'string', 'enum': ['very_positive', 'positive', 'neutral', 'negative', 'very_negative']},\n",
        "                    'response_urgency': {'type': 'string', 'enum': ['immediate', 'within_24h', 'within_week', 'standard']},\n",
        "                    'issue_resolved': {'type': 'string', 'enum': ['fully_resolved', 'partially_resolved', 'unresolved', 'follow_up_scheduled']},\n",
        "                    'next_steps': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Specific action items identified'},\n",
        "                    'follow_up_required': {'type': 'boolean'},\n",
        "                    'escalation_needed': {'type': 'boolean'},\n",
        "                    'customer_satisfaction_indicators': {'type': 'array', 'items': {'type': 'string'}},\n",
        "                    'communication_outcome': {'type': 'string', 'enum': ['successful', 'unsuccessful', 'pending_resolution']},\n",
        "                    'action_items_for_agent': {'type': 'array', 'items': {'type': 'string'}},\n",
        "                    'business_impact': {'type': 'string', 'enum': ['high', 'medium', 'low']},\n",
        "                    'competitive_mentions': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Any competitor mentions'},\n",
        "                    'upsell_opportunities': {'type': 'array', 'items': {'type': 'string'}}\n",
        "                },\n",
        "                'required': ['communication_summary', 'key_topics_discussed', 'customer_sentiment', 'response_urgency', 'issue_resolved', 'next_steps', 'follow_up_required', 'escalation_needed']\n",
        "            }\n",
        "        }\n",
        "    ) AS comprehensive_intelligence\n",
        "FROM EMAIL_PRIORITY_ANALYSIS epa;\n",
        "\n",
        "-- Display the comprehensive intelligence results\n",
        "SELECT \n",
        "    EMAIL_ID,\n",
        "    comprehensive_intelligence\n",
        "FROM COMPREHENSIVE_EMAIL_INTELLIGENCE;\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ðŸ”— Combined AI Operations - Power of Function Combinations\n",
        "\n",
        "Now let's demonstrate the real power of Snowflake's AI platform by combining multiple functions to create advanced business insights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Combination 1: AI_FILTER + AI_AGG - Analyze patterns in escalation-required emails\n",
        "SELECT \n",
        "    'Escalation Pattern Analysis' AS analysis_type,\n",
        "    AI_AGG(\n",
        "        CONCAT('Email ID: ', cei.EMAIL_ID, ', Customer ID: ', cei.CUSTOMER_ID, ', Date: ', cei.DATE_RECEIVED, '. Summary: ', cei.executive_summary),\n",
        "        'Analyze these escalation-required customer emails and identify common patterns, triggers, and recommendations for preventing future escalations. Provide actionable insights for customer service management.'\n",
        "    ) AS escalation_insights\n",
        "FROM COMPREHENSIVE_EMAIL_INTELLIGENCE cei\n",
        "WHERE cei.comprehensive_intelligence:escalation_needed = TRUE;\n",
        "\n",
        "-- Combination 2: AI_CLASSIFY + AI_FILTER - Find complaint emails with negative sentiment\n",
        "SELECT \n",
        "    'Complaint Analysis' AS analysis_type,\n",
        "    email_classification,\n",
        "    sentiment_category,\n",
        "    COUNT(*) AS email_count,\n",
        "    AI_AGG(\n",
        "        CONCAT('Customer ID: ', CUSTOMER_ID, ', Date: ', DATE_RECEIVED, '. Summary: ', executive_summary),\n",
        "        'Summarize the key issues in these negative complaint emails and provide recommendations for improving customer satisfaction and reducing complaint volume.'\n",
        "    ) AS complaint_improvement_recommendations\n",
        "FROM COMPREHENSIVE_EMAIL_INTELLIGENCE\n",
        "WHERE email_classification = 'Complaint'\n",
        "  AND sentiment_category = 'ðŸ˜ž Negative'\n",
        "GROUP BY email_classification, sentiment_category;\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ðŸ“Š Interactive Results Dashboard\n",
        "\n",
        "Let's create an interactive display showing the power of our AI analysis competing with GONG's capabilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create interactive dashboard displaying our AI-powered customer service analytics\n",
        "st.markdown(\"### ðŸš€ GONG-Competitive Customer Service Intelligence Dashboard\")\n",
        "\n",
        "# Get comprehensive intelligence data\n",
        "intelligence_df = session.table('COMPREHENSIVE_EMAIL_INTELLIGENCE').to_pandas()\n",
        "\n",
        "if not intelligence_df.empty:\n",
        "    # Summary metrics\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "    \n",
        "    with col1:\n",
        "        st.metric(\"ðŸ“§ Total Emails Analyzed\", len(intelligence_df))\n",
        "    \n",
        "    with col2:\n",
        "        avg_sentiment = intelligence_df['SENTIMENT_SCORE'].mean()\n",
        "        st.metric(\"ðŸ˜Š Avg Sentiment Score\", f\"{avg_sentiment:.2f}\")\n",
        "    \n",
        "    with col3:\n",
        "        # Count emails by classification\n",
        "        classification_counts = intelligence_df['EMAIL_CLASSIFICATION'].value_counts()\n",
        "        top_category = classification_counts.index[0] if len(classification_counts) > 0 else \"N/A\"\n",
        "        st.metric(\"ðŸ·ï¸ Top Email Type\", top_category)\n",
        "    \n",
        "    with col4:\n",
        "        # Parse JSON to count escalations needed\n",
        "        escalation_count = 0\n",
        "        for idx, row in intelligence_df.iterrows():\n",
        "            try:\n",
        "                intel_data = json.loads(row['COMPREHENSIVE_INTELLIGENCE'])\n",
        "                if intel_data.get('escalation_needed', False):\n",
        "                    escalation_count += 1\n",
        "            except:\n",
        "                pass\n",
        "        st.metric(\"ðŸš¨ Escalations Needed\", escalation_count)\n",
        "    \n",
        "    # Detailed email analysis\n",
        "    st.markdown(\"### ðŸ“‹ Detailed Customer Communication Intelligence\")\n",
        "    \n",
        "    for idx, row in intelligence_df.iterrows():\n",
        "        # Parse intelligence data to get customer info\n",
        "        customer_name = \"Unknown\"\n",
        "        customer_email = \"Unknown\"\n",
        "        try:\n",
        "            intel_data = json.loads(row['COMPREHENSIVE_INTELLIGENCE'])\n",
        "            customer_name = intel_data.get('customer_name', 'Unknown')\n",
        "            customer_email = intel_data.get('customer_email', 'Unknown')\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        with st.expander(f\"ðŸ“§ {row['EMAIL_ID']} - {customer_name} ({row['EMAIL_CLASSIFICATION']})\", expanded=False):\n",
        "            # Customer Information Header\n",
        "            st.markdown(\"**ðŸ” Customer Information**\")\n",
        "            customer_col1, customer_col2, customer_col3 = st.columns(3)\n",
        "            with customer_col1:\n",
        "                st.info(f\"ðŸ‘¤ **Customer:** {customer_name}\")\n",
        "            with customer_col2:\n",
        "                st.info(f\"ðŸ“§ **Email:** {customer_email}\")\n",
        "            with customer_col3:\n",
        "                st.info(f\"ðŸ“… **Date:** {row['DATE_RECEIVED']}\")\n",
        "            \n",
        "            st.markdown(\"---\")  # Separator\n",
        "            \n",
        "            col_left, col_right = st.columns(2)\n",
        "            \n",
        "            with col_left:\n",
        "                st.write(\"**ðŸ“„ Executive Summary:**\")\n",
        "                st.write(row['EXECUTIVE_SUMMARY'])\n",
        "                st.write(f\"**ðŸ˜Š Sentiment:** {row['SENTIMENT_SCORE']:.2f}\")\n",
        "                st.write(f\"**ðŸ·ï¸ Classification:** {row['EMAIL_CLASSIFICATION']}\")\n",
        "                st.write(f\"**ðŸ†” Customer ID:** {row['CUSTOMER_ID']}\")\n",
        "            \n",
        "            with col_right:\n",
        "                st.write(\"**ðŸ¤– AI Intelligence Analysis:**\")\n",
        "                try:\n",
        "                    intel_data = json.loads(row['COMPREHENSIVE_INTELLIGENCE'])\n",
        "                    \n",
        "                    # Display key insights\n",
        "                    if 'communication_summary' in intel_data:\n",
        "                        st.write(f\"**ðŸ“‹ Communication Summary:** {intel_data['communication_summary']}\")\n",
        "                    \n",
        "                    if 'key_topics_discussed' in intel_data:\n",
        "                        st.write(f\"**ðŸ”‘ Key Topics:** {', '.join(intel_data['key_topics_discussed'])}\")\n",
        "                    \n",
        "                    if 'next_steps' in intel_data:\n",
        "                        st.write(f\"**âž¡ï¸ Next Steps:** {', '.join(intel_data['next_steps'])}\")\n",
        "                    \n",
        "                    if 'response_urgency' in intel_data:\n",
        "                        urgency_emoji = {\n",
        "                            'immediate': 'ðŸ”´',\n",
        "                            'within_24h': 'ðŸŸ¡', \n",
        "                            'within_week': 'ðŸŸ ',\n",
        "                            'standard': 'ðŸŸ¢'\n",
        "                        }\n",
        "                        urgency = intel_data['response_urgency']\n",
        "                        st.write(f\"**â° Response Urgency:** {urgency_emoji.get(urgency, 'âšª')} {urgency}\")\n",
        "                    \n",
        "                    if 'business_impact' in intel_data:\n",
        "                        impact_emoji = {'high': 'ðŸ”´', 'medium': 'ðŸŸ¡', 'low': 'ðŸŸ¢'}\n",
        "                        impact = intel_data['business_impact']\n",
        "                        st.write(f\"**ðŸ’¼ Business Impact:** {impact_emoji.get(impact, 'âšª')} {impact}\")\n",
        "                    \n",
        "                    if 'escalation_needed' in intel_data:\n",
        "                        escalation = \"Yes ðŸš¨\" if intel_data['escalation_needed'] else \"No âœ…\"\n",
        "                        st.write(f\"**ðŸš¨ Escalation Needed:** {escalation}\")\n",
        "                    \n",
        "                    if 'follow_up_required' in intel_data:\n",
        "                        followup = \"Yes ðŸ“ž\" if intel_data['follow_up_required'] else \"No âœ…\"\n",
        "                        st.write(f\"**ðŸ“ž Follow-up Required:** {followup}\")\n",
        "                        \n",
        "                except json.JSONDecodeError:\n",
        "                    st.write(\"Raw intelligence data:\")\n",
        "                    st.write(row['COMPREHENSIVE_INTELLIGENCE'])\n",
        "    \n",
        "    st.success(\"ðŸŽ‰ Advanced call center AI analytics completed! This demonstrates enterprise-grade conversation intelligence competing with GONG.\")\n",
        "    \n",
        "else:\n",
        "    st.error(\"No intelligence data found. Please run the previous analysis steps.\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ðŸ”§ Flattening Semi-Structured Intelligence Data\n",
        "\n",
        "Now let's flatten the comprehensive intelligence JSON data into structured columns for easier analysis and reporting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Create a flattened view of the comprehensive intelligence data\n",
        "CREATE OR REPLACE VIEW FLATTENED_EMAIL_INTELLIGENCE AS\n",
        "SELECT \n",
        "    -- Original columns\n",
        "    EMAIL_ID,\n",
        "    CUSTOMER_ID,\n",
        "    DATE_RECEIVED,\n",
        "    EMAIL_CONTENTS,\n",
        "    executive_summary,\n",
        "    sentiment_score,\n",
        "    email_classification,\n",
        "    \n",
        "    -- Flattened JSON fields - Simple values\n",
        "    comprehensive_intelligence:customer_name::STRING AS customer_name,\n",
        "    comprehensive_intelligence:customer_email::STRING AS customer_email,\n",
        "    comprehensive_intelligence:communication_summary::STRING AS communication_summary,\n",
        "    comprehensive_intelligence:customer_sentiment::STRING AS ai_customer_sentiment,\n",
        "    comprehensive_intelligence:response_urgency::STRING AS response_urgency,\n",
        "    comprehensive_intelligence:issue_resolved::STRING AS issue_resolved,\n",
        "    comprehensive_intelligence:business_impact::STRING AS business_impact,\n",
        "    comprehensive_intelligence:communication_outcome::STRING AS communication_outcome,\n",
        "    comprehensive_intelligence:follow_up_required::BOOLEAN AS follow_up_required,\n",
        "    comprehensive_intelligence:escalation_needed::BOOLEAN AS escalation_needed,\n",
        "    \n",
        "    -- Array fields converted to comma-separated strings\n",
        "    ARRAY_TO_STRING(\n",
        "        PARSE_JSON(comprehensive_intelligence:key_topics_discussed), ', '\n",
        "    ) AS key_topics_discussed,\n",
        "    \n",
        "    ARRAY_TO_STRING(\n",
        "        PARSE_JSON(comprehensive_intelligence:next_steps), ', '\n",
        "    ) AS next_steps,\n",
        "    \n",
        "    ARRAY_TO_STRING(\n",
        "        PARSE_JSON(comprehensive_intelligence:action_items_for_agent), ', '\n",
        "    ) AS action_items_for_agent,\n",
        "    \n",
        "    ARRAY_TO_STRING(\n",
        "        PARSE_JSON(comprehensive_intelligence:customer_satisfaction_indicators), ', '\n",
        "    ) AS customer_satisfaction_indicators,\n",
        "    \n",
        "    ARRAY_TO_STRING(\n",
        "        PARSE_JSON(comprehensive_intelligence:competitive_mentions), ', '\n",
        "    ) AS competitive_mentions,\n",
        "    \n",
        "    ARRAY_TO_STRING(\n",
        "        PARSE_JSON(comprehensive_intelligence:upsell_opportunities), ', '\n",
        "    ) AS upsell_opportunities,\n",
        "    \n",
        "    -- Array size counts for analytics\n",
        "    ARRAY_SIZE(PARSE_JSON(comprehensive_intelligence:key_topics_discussed)) AS topic_count,\n",
        "    ARRAY_SIZE(PARSE_JSON(comprehensive_intelligence:next_steps)) AS next_steps_count,\n",
        "    ARRAY_SIZE(PARSE_JSON(comprehensive_intelligence:action_items_for_agent)) AS action_items_count,\n",
        "    ARRAY_SIZE(PARSE_JSON(comprehensive_intelligence:upsell_opportunities)) AS upsell_opportunities_count\n",
        "    \n",
        "FROM COMPREHENSIVE_EMAIL_INTELLIGENCE;\n",
        "\n",
        "-- Display the flattened data\n",
        "SELECT * FROM FLATTENED_EMAIL_INTELLIGENCE LIMIT 5;\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Alternative: Exploding Arrays into Individual Rows\n",
        "\n",
        "For deeper analysis, you might want to explode arrays into individual rows to analyze each topic, action item, or upsell opportunity separately.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Example 1: Explode key topics discussed into individual rows\n",
        "CREATE OR REPLACE VIEW EXPLODED_KEY_TOPICS AS\n",
        "SELECT \n",
        "    EMAIL_ID,\n",
        "    CUSTOMER_ID,\n",
        "    DATE_RECEIVED,\n",
        "    comprehensive_intelligence:customer_name::STRING AS customer_name,\n",
        "    comprehensive_intelligence:customer_email::STRING AS customer_email,\n",
        "    comprehensive_intelligence:business_impact::STRING AS business_impact,\n",
        "    f.value::STRING AS individual_topic\n",
        "FROM COMPREHENSIVE_EMAIL_INTELLIGENCE,\n",
        "LATERAL FLATTEN(input => PARSE_JSON(comprehensive_intelligence:key_topics_discussed)) f;\n",
        "\n",
        "-- Example 2: Explode action items for agents into individual rows\n",
        "CREATE OR REPLACE VIEW EXPLODED_ACTION_ITEMS AS\n",
        "SELECT \n",
        "    EMAIL_ID,\n",
        "    CUSTOMER_ID,\n",
        "    DATE_RECEIVED,\n",
        "    comprehensive_intelligence:customer_name::STRING AS customer_name,\n",
        "    comprehensive_intelligence:response_urgency::STRING AS response_urgency,\n",
        "    comprehensive_intelligence:escalation_needed::BOOLEAN AS escalation_needed,\n",
        "    f.value::STRING AS individual_action_item,\n",
        "    f.index AS action_item_sequence\n",
        "FROM COMPREHENSIVE_EMAIL_INTELLIGENCE,\n",
        "LATERAL FLATTEN(input => PARSE_JSON(comprehensive_intelligence:action_items_for_agent)) f;\n",
        "\n",
        "-- Example 3: Explode upsell opportunities into individual rows\n",
        "CREATE OR REPLACE VIEW EXPLODED_UPSELL_OPPORTUNITIES AS\n",
        "SELECT \n",
        "    EMAIL_ID,\n",
        "    CUSTOMER_ID,\n",
        "    DATE_RECEIVED,\n",
        "    comprehensive_intelligence:customer_name::STRING AS customer_name,\n",
        "    comprehensive_intelligence:customer_email::STRING AS customer_email,\n",
        "    comprehensive_intelligence:business_impact::STRING AS business_impact,\n",
        "    f.value::STRING AS individual_upsell_opportunity,\n",
        "    f.index AS opportunity_sequence\n",
        "FROM COMPREHENSIVE_EMAIL_INTELLIGENCE,\n",
        "LATERAL FLATTEN(input => PARSE_JSON(comprehensive_intelligence:upsell_opportunities)) f;\n",
        "\n",
        "-- Display sample results\n",
        "SELECT 'Key Topics Analysis' AS analysis_type, COUNT(*) AS total_topics \n",
        "FROM EXPLODED_KEY_TOPICS\n",
        "UNION ALL\n",
        "SELECT 'Action Items Analysis' AS analysis_type, COUNT(*) AS total_action_items \n",
        "FROM EXPLODED_ACTION_ITEMS\n",
        "UNION ALL\n",
        "SELECT 'Upsell Opportunities Analysis' AS analysis_type, COUNT(*) AS total_opportunities \n",
        "FROM EXPLODED_UPSELL_OPPORTUNITIES;\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### Advanced Analytics on Flattened Data\n",
        "\n",
        "Now let's perform some advanced analytics using the flattened data structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "sql"
        }
      },
      "outputs": [],
      "source": [
        "-- Analytics Query 1: Customer Response Urgency Analysis\n",
        "SELECT \n",
        "    response_urgency,\n",
        "    COUNT(*) AS email_count,\n",
        "    AVG(sentiment_score) AS avg_sentiment,\n",
        "    SUM(CASE WHEN escalation_needed THEN 1 ELSE 0 END) AS escalation_count,\n",
        "    SUM(CASE WHEN follow_up_required THEN 1 ELSE 0 END) AS followup_count,\n",
        "    AVG(action_items_count) AS avg_action_items,\n",
        "    AVG(upsell_opportunities_count) AS avg_upsell_opportunities\n",
        "FROM FLATTENED_EMAIL_INTELLIGENCE\n",
        "GROUP BY response_urgency\n",
        "ORDER BY \n",
        "    CASE response_urgency \n",
        "        WHEN 'immediate' THEN 1 \n",
        "        WHEN 'within_24h' THEN 2 \n",
        "        WHEN 'within_week' THEN 3 \n",
        "        WHEN 'standard' THEN 4 \n",
        "        ELSE 5 \n",
        "    END;\n",
        "\n",
        "-- Analytics Query 2: Business Impact vs Customer Sentiment Analysis\n",
        "SELECT \n",
        "    business_impact,\n",
        "    ai_customer_sentiment,\n",
        "    COUNT(*) AS email_count,\n",
        "    AVG(sentiment_score) AS avg_snowflake_sentiment,\n",
        "    AVG(topic_count) AS avg_topics_discussed,\n",
        "    ROUND(AVG(upsell_opportunities_count), 2) AS avg_upsell_ops\n",
        "FROM FLATTENED_EMAIL_INTELLIGENCE\n",
        "WHERE business_impact IS NOT NULL AND ai_customer_sentiment IS NOT NULL\n",
        "GROUP BY business_impact, ai_customer_sentiment\n",
        "ORDER BY business_impact, ai_customer_sentiment;\n",
        "\n",
        "-- Analytics Query 3: Top Discussion Topics Analysis\n",
        "SELECT \n",
        "    individual_topic,\n",
        "    COUNT(*) AS frequency,\n",
        "    AVG(CASE WHEN business_impact = 'high' THEN 1 ELSE 0 END) AS high_impact_rate,\n",
        "    COUNT(DISTINCT customer_name) AS unique_customers\n",
        "FROM EXPLODED_KEY_TOPICS\n",
        "WHERE individual_topic IS NOT NULL\n",
        "GROUP BY individual_topic\n",
        "HAVING COUNT(*) >= 2  -- Only topics mentioned multiple times\n",
        "ORDER BY frequency DESC\n",
        "LIMIT 10;\n",
        "\n",
        "-- Analytics Query 4: Customer Escalation Patterns\n",
        "SELECT \n",
        "    customer_name,\n",
        "    customer_email,\n",
        "    COUNT(*) AS total_emails,\n",
        "    SUM(CASE WHEN escalation_needed THEN 1 ELSE 0 END) AS escalation_count,\n",
        "    AVG(sentiment_score) AS avg_sentiment,\n",
        "    MAX(DATE_RECEIVED) AS last_contact_date,\n",
        "    SUM(action_items_count) AS total_action_items\n",
        "FROM FLATTENED_EMAIL_INTELLIGENCE\n",
        "WHERE customer_name IS NOT NULL\n",
        "GROUP BY customer_name, customer_email\n",
        "HAVING COUNT(*) > 1  -- Customers with multiple emails\n",
        "ORDER BY escalation_count DESC, total_emails DESC;\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
